{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "def calculate_avg_similarity(model, reference_sentences, model_outputs):\n",
        "    \"\"\"\n",
        "    Calculates the average cosine similarity between a list of reference\n",
        "    sentences and a corresponding list of model output sentences.\n",
        "    \"\"\"\n",
        "    if len(reference_sentences) != len(model_outputs):\n",
        "        print(f\"Error: Mismatched list lengths. {len(reference_sentences)} references vs {len(model_outputs)} outputs.\")\n",
        "        return 0.0\n",
        "\n",
        "    reference_embeddings = model.encode(reference_sentences, convert_to_tensor=True)\n",
        "    output_embeddings = model.encode(model_outputs, convert_to_tensor=True)\n",
        "    cosine_scores = util.cos_sim(reference_embeddings, output_embeddings)\n",
        "    paired_scores = [cosine_scores[i][i].item() for i in range(len(reference_sentences))]\n",
        "    return np.mean(paired_scores)\n",
        "\n",
        "\n",
        "# --- 1. DEFINE YOUR DATA ---\n",
        "\n",
        "reference_style_sentences = [\n",
        "    \"This imagined story of one is the real experience of many. It is rarely a surprise to see the campus buzzing with energy past midnight, whether it's the chatter at Aromas or the tables at the Reading Hall\",\n",
        "    \"The institute has a sense of beauty even in those wee hours before sunrise, as one appreciates the thriving student culture that has existed at IITB since time immemorial\",\n",
        "    \"That nighttime grind, however, furthers a vicious cycle of sleep deprivation passed down to each batch\",\n",
        "    \"There could be a multitude of reasons for participating in this cycle and losing sleep\",\n",
        "    \"A good percentage of us suffer from this pattern quite regularly, sometimes for days or even weeks on end. As a result, a lot of the instizens seem visibly afflicted with chronic fatigue\",\n",
        "    \"Don’t get us wrong, unlike some other nosy figures in the institute, the intent here is not to push the agenda of ‘students must sleep on time,’ and in the process, dismantle all of the spotty yet admirable legacy we have built, particularly in freedom\",\n",
        "    \"This article is not a lecture on sleeping on time - it is rather an attempt to understand if the issue is purely conceived out of choice, or systematic problems beyond our control\"\n",
        "]\n",
        "\n",
        "three_shot_outputs = [\n",
        "    \"What may appear as an individual eccentricity is, in truth, a collective choreography. The campus, after dusk, hums with a peculiar brilliance—from the soft murmur at Aromas to the unbroken stillness of the Reading Hall—an order so ingrained it transcends mere habit, becoming heritage.\",\n",
        "    \"There exists an ineffable gravitas in IIT Bombay’s pre-dawn hours—a quiet sanctity preserved through generations, where sleeplessness has been reimagined not as deprivation, but as devotion.\",\n",
        "    \"Yet this ritual of wakefulness, noble in its intent, sustains a lineage of exhaustion—a cycle handed down, batch after batch, its toll etched into weary eyes and unspoken resignation.\",\n",
        "    \"The impulses sustaining this rhythm are manifold: ambition cloaked as purpose, anxiety disguised as diligence, and the silent companionship of those unwilling to be left behind in the race for significance.\",\n",
        "    \"A considerable portion of the populace remains ensnared in this cadence for months, even years—until fatigue itself becomes a badge, worn with the quiet pride of endurance.\",\n",
        "    \"Let it be said—this is no moral plea for early rest, nor an assault on the sanctified autonomy of the nocturnal scholar. The right to sculpt one’s own rhythm remains a freedom too dearly earned to be tampered with.\",\n",
        "    \"This meditation, then, is not on sleep, but on agency. Whether this sleepless fervor is an act of will or a symptom of unseen design remains the question that shadows every glowing screen at 3 a.m.\"\n",
        "]\n",
        "\n",
        "PEFT_phi_outputs = [\n",
        "    \"This is the kind of experience that many students go through, with them often being found hanging out at places like Aromas or the Reading Hall past midnight\",\n",
        "    \"This charm is especially evident in the pre-dawn hours when one can sense the long-standing culture of IITB where students go beyond just learning to code.\",\n",
        "    \"While this kind of nocturnal study also perpetuates the cycle of Sleep deprivation, feeding into the very problem.\",\n",
        "    \"The reasons for the same are manifold.\",\n",
        "    \"This is a problem that a significant portion of the population faces, often for extended periods, leading to an epidemic of chronic fatigue.\",\n",
        "    \"It’s not about imposing a specific bedtime, akin to other such attempts to control student life.\",\n",
        "    \"This is not just a column on sleep schedules, but rather a question of whether this is a matter of choice or a symptom of a larger problem.\"\n",
        "]\n",
        "\n",
        "# --- 2. LOAD MODEL ---\n",
        "model_name = 'paraphrase-mpnet-base-v2'\n",
        "print(f\"Loading model: {model_name}...\")\n",
        "model = SentenceTransformer(model_name)\n",
        "print(\"Model loaded.\")\n",
        "\n",
        "# --- 3. CALCULATE SIMILARITIES ---\n",
        "print(\"Calculating similarities...\")\n",
        "avg_sim_model_a = calculate_avg_similarity(model, reference_style_sentences, model_a_outputs)\n",
        "avg_sim_model_b = calculate_avg_similarity(model, reference_style_sentences, model_b_outputs)\n",
        "\n",
        "# --- 4. DISPLAY RESULTS ---\n",
        "print(\"\\n--- Style Evaluation Results ---\")\n",
        "print(\"Average cosine similarity of each model's output vs reference style sentences:\\n\")\n",
        "print(f\"{'Model':<20} | {'Avg. Cosine Similarity':<25}\")\n",
        "print(\"-\" * 47)\n",
        "print(f\"{'few shot prompting chat gpt 5':<20} | {avg_sim_model_a:<25.4f}\")\n",
        "print(f\"{'Fine-tuned Model phi 3.5':<20} | {avg_sim_model_b:<25.4f}\")\n",
        "\n",
        "print(\"\\n--- Interpretation ---\")\n",
        "models = {\n",
        "    \"few shot prompting chat gpt 5\": avg_sim_model_a,\n",
        "    \"Fine-tuned Model phi 3.5\": avg_sim_model_b\n",
        "}\n",
        "best_model = max(models, key=models.get)\n",
        "best_score = models[best_model]\n",
        "\n",
        "print(f\"✅ {best_model} (Score: {best_score:.4f}) shows the highest similarity.\")\n",
        "print(\"This indicates its style is the closest to your reference sentences.\")\n",
        "print(\"\\nA higher score means the model's output style is more similar to your reference style.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXENHlE9r5iu",
        "outputId": "62c7a071-1d0b-4ca0-aa68-7597d1265fea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model: paraphrase-mpnet-base-v2...\n",
            "Model loaded.\n",
            "Calculating similarities...\n",
            "\n",
            "--- Style Evaluation Results ---\n",
            "Average cosine similarity of each model's output vs reference style sentences:\n",
            "\n",
            "Model                | Avg. Cosine Similarity   \n",
            "-----------------------------------------------\n",
            "few shot prompting chat gpt 5 | 0.5874                   \n",
            "Fine-tuned Model phi 3.5 | 0.7020                   \n",
            "\n",
            "--- Interpretation ---\n",
            "✅ Fine-tuned Model phi 3.5 (Score: 0.7020) shows the highest similarity.\n",
            "This indicates its style is the closest to your reference sentences.\n",
            "\n",
            "A higher score means the model's output style is more similar to your reference style.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21Rbbn2uGrMT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}