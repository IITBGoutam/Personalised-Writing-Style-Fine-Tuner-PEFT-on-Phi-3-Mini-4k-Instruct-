{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ee13ec-22d7-4b7e-9d45-218c4200feb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "✅ Done! 75 style samples saved to 'my_style_raw.txt'.\n"
     ]
    }
   ],
   "source": [
    "# convert_to_style_format.py\n",
    "#\"D:\\machine learning\\PEFT LORA PHI - ARTICLE WRITER\\my_article.txt\"\n",
    "input_file = \"my_article.txt\"        # your input article file\n",
    "output_file = \"my_style_raw.txt\"     # formatted output file\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "# Split by periods (.)\n",
    "sentences = text.split(\".\")\n",
    "\n",
    "\n",
    "# Clean and filter short/empty lines\n",
    "sentences = [s.strip() for s in sentences if len(s.strip()) > 5]\n",
    "print(len(sentences))\n",
    "# Write in [STYLE_SAMPLE] format\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for s in sentences:\n",
    "        f.write(f\"[STYLE_SAMPLE]\\n{s.strip()}.\\n\\n\")\n",
    "\n",
    "print(f\"✅ Done! {len(sentences)} style samples saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03179830-baed-4285-828d-f8bdac149837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading GPT-style samples from: gimini_style.txt\n",
      "Reading my-style samples from: my_style_raw.txt\n",
      "GPT samples found: 75\n",
      "My style samples found: 75\n",
      "Paired samples: 75\n",
      "Writing train (68) and val (7) files.\n",
      "Wrote dataset to: style_dataset.jsonl\n",
      "Wrote train to: train.jsonl val to: val.jsonl\n",
      "\n",
      "EXAMPLE records:\n",
      "---\n",
      "IN : The burgeoning landscape of AI tools presents an evolving challenge for educators and students alike, with definitive guidelines for their use still taking shape. Despite this fluidity, a broad consensus among professors underscores that reliance on these technologies without cultivating original thought or profound understanding ultimately undermines sustainable success.\n",
      "OUT: As these tools are still emerging and it is tough to deterministically say what is the correct way to use them, however, ...\n",
      "---\n",
      "IN : Alok Takkar's proposal, while acknowledged as an intriguing concept, faces an admitted challenge: students could still circumvent the measure by memorizing LLM-generated output for in-lab reproduction. Nevertheless, Takkar maintains the belief that it would create sufficient deterrence.\n",
      "OUT: ” -Alok Takkar While an interesting idea, Alok himself admits that students could still memorise the LLM's output and ty ...\n",
      "---\n",
      "IN : Across university campuses, many professors are discerning effective, if not radical, applications for large language models in their teaching. This growing cohort of educators is actively integrating AI tools, forging new pedagogical pathways and evolving traditional classroom approaches.\n",
      "OUT: Most professors, while not this radical, have also found interesting ways to use LLMs in their teaching. \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "build_style_dataset.py\n",
    "\n",
    "Expect two input files (both using blocks like):\n",
    "[STYLE_SAMPLE]\n",
    "Some text here.\n",
    "\n",
    "[STYLE_SAMPLE]\n",
    "Another text here.\n",
    "\n",
    "One file should contain the \"GPT-style\" (plain) lines, the other file should\n",
    "contain your \"my-style\" lines. They are paired in order (1st -> 1st, 2nd -> 2nd).\n",
    "\n",
    "Output: style_dataset.jsonl (one json per line: instruction,input,output)\n",
    "Also optionally splits into train/val.\n",
    "\"\"\"\n",
    "\n",
    "import json, re, os, random\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------- SETTINGS (edit if needed) ----------\n",
    "gpt_file = \"gimini_style.txt\"        # file with generic ChatGPT-style rephrasings\n",
    "my_file  = \"my_style_raw.txt\"         # file with your style samples (targets)\n",
    "out_file = \"style_dataset.jsonl\"  # final dataset\n",
    "train_file = \"train.jsonl\"\n",
    "val_file = \"val.jsonl\"\n",
    "val_frac = 0.10                   # fraction to reserve for validation (0.0 to 0.5)\n",
    "min_len_chars = 10                # minimum characters to accept a sample\n",
    "shuffle_seed = 42\n",
    "# ------------------------------------------------\n",
    "\n",
    "def read_style_blocks(path):\n",
    "    \"\"\"Read file and return list of blocks under [STYLE_SAMPLE] markers.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"{path} not found\")\n",
    "    text = Path(path).read_text(encoding=\"utf-8\").lstrip(\"\\ufeff\")\n",
    "    # split on [STYLE_SAMPLE] (case-insensitive)\n",
    "    parts = re.split(r'(?i)\\[STYLE_SAMPLE\\]', text)\n",
    "    samples = []\n",
    "    for p in parts:\n",
    "        s = p.strip()\n",
    "        if not s:\n",
    "            continue\n",
    "        # remove leading punctuation/newlines and trailing whitespace\n",
    "        s = re.sub(r'^\\s*[:\\-–—\\.\\n]+', '', s).strip()\n",
    "        s = re.sub(r'\\s+', ' ', s)  # collapse whitespace\n",
    "        # ensure sentence ends with punctuation for safety\n",
    "        if not re.search(r'[.!?]$', s):\n",
    "            s = s + '.'\n",
    "        if len(s) >= min_len_chars:\n",
    "            samples.append(s)\n",
    "    return samples\n",
    "\n",
    "def build_pairs(gpt_samples, my_samples):\n",
    "    if len(gpt_samples) != len(my_samples):\n",
    "        print(f\"Warning: counts differ — GPT samples: {len(gpt_samples)}, My samples: {len(my_samples)}\")\n",
    "        # pair up to min length\n",
    "    n = min(len(gpt_samples), len(my_samples))\n",
    "    pairs = [(gpt_samples[i], my_samples[i]) for i in range(n)]\n",
    "    return pairs\n",
    "\n",
    "def write_jsonl(records, path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in records:\n",
    "            f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    print(\"Reading GPT-style samples from:\", gpt_file)\n",
    "    gpt_samples = read_style_blocks(gpt_file)\n",
    "    print(\"Reading my-style samples from:\", my_file)\n",
    "    my_samples = read_style_blocks(my_file)\n",
    "    print(\"GPT samples found:\", len(gpt_samples))\n",
    "    print(\"My style samples found:\", len(my_samples))\n",
    "\n",
    "    pairs = build_pairs(gpt_samples, my_samples)\n",
    "    print(\"Paired samples:\", len(pairs))\n",
    "    if len(pairs) == 0:\n",
    "        print(\"No pairs to write. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Build records\n",
    "    records = []\n",
    "    for gpt_text, my_text in pairs:\n",
    "        # Instruction can be tuned; keep concise and explicit\n",
    "        record = {\n",
    "            \"instruction\": \"Rewrite the following text in Goutam's writing style.\",\n",
    "            \"input\": gpt_text,\n",
    "            \"output\": my_text\n",
    "        }\n",
    "        # alternative formats:\n",
    "        # {\"prompt\": f\"Rewrite in my style: {gpt_text}\", \"completion\": my_text}\n",
    "        records.append(record)\n",
    "\n",
    "    # Shuffle deterministically then split\n",
    "    random.Random(shuffle_seed).shuffle(records)\n",
    "    if 0.0 < val_frac < 0.5:\n",
    "        n_val = max(1, int(len(records) * val_frac))\n",
    "        val = records[:n_val]\n",
    "        train = records[n_val:]\n",
    "        print(f\"Writing train ({len(train)}) and val ({len(val)}) files.\")\n",
    "        write_jsonl(train, train_file)\n",
    "        write_jsonl(val, val_file)\n",
    "    else:\n",
    "        print(f\"No validation split requested (val_frac={val_frac}). Writing full dataset.\")\n",
    "\n",
    "    # write main dataset file (shuffled)\n",
    "    write_jsonl(records, out_file)\n",
    "    print(\"Wrote dataset to:\", out_file)\n",
    "    if os.path.exists(train_file):\n",
    "        print(\"Wrote train to:\", train_file, \"val to:\", val_file)\n",
    "\n",
    "    # show first 3 records as sanity check\n",
    "    print(\"\\nEXAMPLE records:\")\n",
    "    for i, r in enumerate(records[:3]):\n",
    "        print(\"---\")\n",
    "        print(\"IN :\", r['input'])\n",
    "        print(\"OUT:\", r['output'][:120], \"...\" if len(r['output'])>120 else \"\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ceadb1d4-0274-44f4-9e63-8719f6a91ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Input and output files\n",
    "input_file = \"style_dataset.jsonl\"   # your JSONL input\n",
    "output_file = \"phi3_finetune_format.txt\"    # Phi-3 compatible text format\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f_in, open(output_file, \"w\", encoding=\"utf-8\") as f_out:\n",
    "    for line in f_in:\n",
    "        example = json.loads(line)\n",
    "        instruction = example.get(\"instruction\", \"\").strip()\n",
    "        inp = example.get(\"input\", \"\").strip()\n",
    "        output = example.get(\"output\", \"\").strip()\n",
    "\n",
    "        # Merge instruction + input as user message\n",
    "        user_message = instruction\n",
    "        if inp:\n",
    "            user_message += \"\\n\" + inp\n",
    "\n",
    "        # Write in Phi-3 chat style\n",
    "        formatted = (\n",
    "            f\"<|user|>\\n{user_message}\\n<|end|>\\n\"\n",
    "            f\"<|assistant|>\\n{output}\\n<|end|>\\n\"\n",
    "        )\n",
    "        f_out.write(formatted + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f8d45-321e-4246-9dd5-383cb16feb0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
